{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-31T02:58:47.982187800Z",
     "start_time": "2024-10-31T02:58:47.962882700Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch import tensor\n",
    "import torch.utils.data as Data\n",
    "import math\n",
    "from matplotlib import pyplot\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']  # 用来正常显示中文标签\n",
    "plt.rcParams['axes.unicode_minus'] = False  # 用来正常显示负号\n",
    "import pandas as pd\n",
    "\n",
    "# 设置随机参数：保证实验结果可以重复\n",
    "SEED = 1234\n",
    "import random\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)  # 适用于显卡训练\n",
    "torch.cuda.manual_seed_all(SEED)  # 适用于多显卡训练\n",
    "from torch.backends import cudnn\n",
    "\n",
    "cudnn.benchmark = False\n",
    "cudnn.deterministic = True\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cuda')"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-31T02:58:45.191251600Z",
     "start_time": "2024-10-31T02:58:45.152395100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.5 77.  24.  57.   9.  54. ]\n",
      "1.5\n"
     ]
    }
   ],
   "source": [
    "filepath = '../data/DataProcess/station/1037A/1037A-2020-new.csv'\n",
    "data = pd.read_csv(filepath)\n",
    "data = data[['CO', 'PM10', 'SO2', 'NO2', 'O3', 'PM2.5']].values\n",
    "print(data[0])\n",
    "print(data[0][0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-31T02:58:49.961915Z",
     "start_time": "2024-10-31T02:58:49.935189500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8296 8296\n",
      "[array([ 1.5, 77. , 24. , 57. ,  9. , 54. ]), array([ 1.3, 84. , 21. , 56. ,  8. , 51. ]), array([ 1.5, 97. , 24. , 58. ,  8. , 55. ])]\n",
      "60.0\n"
     ]
    }
   ],
   "source": [
    "# 5个数据划分一组，前4个预测后一个\n",
    "sqe_len = 3\n",
    "len_int = 6\n",
    "data_2_x = []\n",
    "data_2_y = []\n",
    "for i in range(0, len(data) - 5, 1):  # 步长为5  （0：len(data_y） 不包含 len(data_y)\n",
    "    temp_x = []\n",
    "    temp_x.append(data[i][:])\n",
    "    temp_x.append(data[i + 1][:])\n",
    "    temp_x.append(data[i + 2][:])\n",
    "    # temp_x.append(data[i + 3][:-1])\n",
    "    data_2_x.append(temp_x)\n",
    "\n",
    "    data_2_y.append(data[i + 3][-1])\n",
    "\n",
    "print(len(data_2_x), len(data_2_y))\n",
    "print(data_2_x[0])\n",
    "print(data_2_y[0])\n",
    "data_2_x = np.array(data_2_x)  #,dtype=float)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-31T02:58:51.454003200Z",
     "start_time": "2024-10-31T02:58:51.419860300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "class DataSet(Data.Dataset):  # 数据加载类\n",
    "    def __init__(self, data_inputs, data_targets):\n",
    "        self.inputs = torch.FloatTensor(data_inputs)\n",
    "        self.label = torch.FloatTensor(data_targets)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.inputs[index], self.label[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-31T02:58:53.152258900Z",
     "start_time": "2024-10-31T02:58:53.123693600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TestDataLoader 的batch个数 6\n",
      "TrainDataLoader 的batch个数 25\n",
      "np.array(data_2_x).shape (8296, 3, 6)\n"
     ]
    }
   ],
   "source": [
    "Batch_Size = 256  #\n",
    "DataSet = DataSet(np.array(data_2_x), list(data_2_y))\n",
    "train_size = int(len(data_2_y) * 0.8)  # 自己计算\n",
    "test_size = len(data_2_y) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(DataSet, [train_size, test_size])\n",
    "TrainDataLoader = Data.DataLoader(train_dataset, batch_size=Batch_Size, shuffle=False, drop_last=True)\n",
    "TestDataLoader = Data.DataLoader(test_dataset, batch_size=Batch_Size, shuffle=False, drop_last=True)\n",
    "print(\"TestDataLoader 的batch个数\", TestDataLoader.__len__())\n",
    "print(\"TrainDataLoader 的batch个数\", TrainDataLoader.__len__())\n",
    "print(\"np.array(data_2_x).shape\", np.array(data_2_x).shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-31T02:58:54.306901800Z",
     "start_time": "2024-10-31T02:58:54.272957400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        # pe.requires_grad = False\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        chunk = x.chunk(x.size(-1), dim=2)\n",
    "        out = torch.Tensor([]).to(x.device)\n",
    "        for i in range(len(chunk)):\n",
    "            out = torch.cat((out, chunk[i] + self.pe[:chunk[i].size(0), ...]), dim=2)\n",
    "        return out\n",
    "\n",
    "\n",
    "def transformer_generate_tgt_mask(length, device):\n",
    "    mask = torch.tril(torch.ones(length, length, device=device)) == 1\n",
    "    mask = (\n",
    "        mask.float()\n",
    "        .masked_fill(mask == 0, float(\"-inf\"))\n",
    "        .masked_fill(mask == 1, float(0.0))\n",
    "    )\n",
    "    return mask\n",
    "\n",
    "\n",
    "class Transformer(nn.Module):  # lstm+transformer+dnn\n",
    "    \"\"\"标准的Transformer编码器-解码器结构\"\"\"\n",
    "\n",
    "    def __init__(self, n_encoder_inputs, n_decoder_inputs, Sequence_length, d_model=512, dropout=0.1, num_layer=8):\n",
    "        \"\"\"\n",
    "        初始化\n",
    "        :param n_encoder_inputs:    输入数据的特征维度\n",
    "        :param n_decoder_inputs:    编码器输入的特征维度，其实等于编码器输出的特征维度\n",
    "        :param d_model:             词嵌入特征维度\n",
    "        :param dropout:             dropout\n",
    "        :param num_layer:           Transformer块的个数\n",
    "         Sequence_length:           transformer 输入数据 序列的长度\n",
    "        \"\"\"\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.input_pos_embedding = torch.nn.Embedding(500, embedding_dim=d_model)\n",
    "        self.target_pos_embedding = torch.nn.Embedding(500, embedding_dim=d_model)\n",
    "\n",
    "        encoder_layer = torch.nn.TransformerEncoderLayer(d_model=d_model, nhead=num_layer, dropout=dropout,\n",
    "                                                         dim_feedforward=4 * d_model)\n",
    "        decoder_layer = torch.nn.TransformerDecoderLayer(d_model=d_model, nhead=num_layer, dropout=dropout,\n",
    "                                                         dim_feedforward=4 * d_model)\n",
    "\n",
    "        self.encoder = torch.nn.TransformerEncoder(encoder_layer, num_layers=2)\n",
    "        self.decoder = torch.nn.TransformerDecoder(decoder_layer, num_layers=4)\n",
    "\n",
    "        self.lstm = nn.LSTM(len_int, len_int, num_layers=1, bidirectional=False)  # ,batch_first=True 是使用双向\n",
    "        self.input_projection = torch.nn.Linear(n_encoder_inputs, d_model)\n",
    "        self.output_projection = torch.nn.Linear(n_decoder_inputs, d_model)\n",
    "\n",
    "        self.linear = torch.nn.Linear(d_model, 1)\n",
    "        self.ziji_add_linear = torch.nn.Linear(Sequence_length, 1)\n",
    "        self.relu = F.relu\n",
    "\n",
    "    def encode_in(self, src):\n",
    "        src_start = self.input_projection(src).permute(1, 0, 2)\n",
    "        in_sequence_len, batch_size = src_start.size(0), src_start.size(1)\n",
    "        pos_encoder = (torch.arange(0, in_sequence_len, device=src.device).unsqueeze(0).repeat(batch_size, 1))\n",
    "        pos_encoder = self.input_pos_embedding(pos_encoder).permute(1, 0, 2)\n",
    "        src = src_start + pos_encoder\n",
    "        src = self.encoder(src) + src_start\n",
    "        return src\n",
    "\n",
    "    def decode_out(self, tgt, memory):\n",
    "        tgt_start = self.output_projection(tgt).permute(1, 0, 2)\n",
    "        out_sequence_len, batch_size = tgt_start.size(0), tgt_start.size(1)\n",
    "        pos_decoder = (torch.arange(0, out_sequence_len, device=tgt.device).unsqueeze(0).repeat(batch_size, 1))\n",
    "        pos_decoder = self.target_pos_embedding(pos_decoder).permute(1, 0, 2)\n",
    "        tgt = tgt_start + pos_decoder\n",
    "        tgt_mask = transformer_generate_tgt_mask(out_sequence_len, tgt.device)\n",
    "        out = self.decoder(tgt=tgt, memory=memory, tgt_mask=tgt_mask) + tgt_start\n",
    "        out = out.permute(1, 0, 2)  # [batch_size, seq_len, d_model]\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "    def forward(self, src, target_in):\n",
    "        # print(\"src.shape\",src.shape)#src.shape torch.Size([9, 8, 512])\n",
    "        lstm_out, (h_n, c_n) = self.lstm(src)\n",
    "        src = self.encode_in(self.relu(lstm_out))\n",
    "        out = self.decode_out(tgt=target_in, memory=src)\n",
    "        # print(\"out.shape\",out.shape)\n",
    "        # print(\"out.shape:\",out.shape)# torch.Size([batch, 3, 1]) # 原本代码中的输出\n",
    "        # 上边的这个输入可以用于很多任务的输出 可以根据任务进行自由的变换\n",
    "        # 下面是自己修改的\n",
    "        # 使用全连接变成 [batch,1] 构成了基于transformer的回归单值预测\n",
    "        out = out.squeeze(2)\n",
    "        out = self.ziji_add_linear(out)\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-31T02:58:55.691465800Z",
     "start_time": "2024-10-31T02:58:55.671329700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "model = Transformer(n_encoder_inputs=len_int, n_decoder_inputs=len_int, Sequence_length=sqe_len).to(\n",
    "    device)  # 3 表示Sequence_length  transformer 输入数据 序列的长度"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-31T02:58:59.450933100Z",
     "start_time": "2024-10-31T02:58:59.279508200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "def test_main(model):\n",
    "    val_epoch_loss = []\n",
    "    with torch.no_grad():\n",
    "        for index, (inputs, targets) in enumerate(TestDataLoader):\n",
    "            inputs = torch.tensor(inputs).to(device)\n",
    "            targets = torch.tensor(targets).to(device)\n",
    "            inputs = inputs.float().to(device)\n",
    "            targets = targets.float().to(device)\n",
    "            tgt_in = torch.ones((Batch_Size, sqe_len, len_int)).to(device)\n",
    "            outputs = model(inputs, tgt_in).to(device)\n",
    "            # print(outputs.float(), targets.float())\n",
    "            loss = criterion(outputs.float(), targets.float())\n",
    "            val_epoch_loss.append(loss.item())\n",
    "    return np.mean(val_epoch_loss)\n",
    "\n",
    "\n",
    "epochs = 50 # 50 100 150 200\n",
    "optimizer = torch.optim.Adagrad(model.parameters(), lr=0.01) # 0.01 0.02 0.03 0.04 0.05\n",
    "criterion = torch.nn.MSELoss().to(device)# MSELoss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-31T03:06:27.505973400Z",
     "start_time": "2024-10-31T03:06:27.484921700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(2187.4695, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2272.3225, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2679.7593, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1329.7354, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1890.7793, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1226.7698, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1069.0745, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1256.4121, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1898.4192, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1737.8719, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2876.4556, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2357.6792, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2226.7180, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2254.5178, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1317.1577, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(908.1421, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1494.6099, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2029.0452, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1422.0774, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(939.5148, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1303.8228, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2056.1707, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1581.2107, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1343.0239, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1822.2877, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [00:02<01:45,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 train_epoch_loss: 1739.2418701171875 val_epoch_loss: 1660.1420084635417\n",
      "best_test_loss ------------------------------------------------- 1660.1420084635417\n",
      "loss: tensor(1910.8911, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1740.5464, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2557.1001, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1319.8896, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1916.7607, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1261.1694, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1139.3317, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1170.5531, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1753.8345, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1490.7866, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2562.9517, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2206.3433, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2095.7151, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2144.0020, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1302.4133, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(915.5121, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1522.3013, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2136.9497, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1415.9504, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(968.5609, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1293.3643, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2180.8755, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1558.8068, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1220.8446, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1758.9196, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch: 1 train_epoch_loss: 1661.7749462890624 val_epoch_loss: 1559.9491373697917\n",
      "best_test_loss ------------------------------------------------- 1559.9491373697917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/50 [00:04<01:34,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1892.6431, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1632.6171, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2531.2312, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1278.1566, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1909.5020, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1290.8289, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1245.9122, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1252.2974, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1835.8945, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1489.8793, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2444.5801, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2245.1812, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2073.8662, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1994.4049, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1350.2554, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(966.7942, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1516.1302, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1996.7051, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1418.7522, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(928.1122, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1268.8801, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2145.4570, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1562.6138, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1234.3927, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3/50 [00:05<01:28,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " tensor(1809.3308, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch: 2 train_epoch_loss: 1652.576728515625 val_epoch_loss: 1608.2449951171875\n",
      "loss: tensor(1991.6008, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1671.6083, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2655.0637, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1323.1389, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1961.3357, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1255.1560, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1067.7614, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1192.0984, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1775.4497, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1510.9501, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2543.4365, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2183.2725, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2043.0085, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2018.2897, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1301.0940, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(944.5105, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1526.0891, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1988.3892, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1493.5815, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(975.9363, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1331.7729, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2057.5225, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1570.0115, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1303.0249, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1783.4147, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4/50 [00:07<01:25,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3 train_epoch_loss: 1658.7006884765624 val_epoch_loss: 1607.2254231770833\n",
      "loss: tensor(1882.6478, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1682.6007, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2535.1543, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1288.3677, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1901.1638, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1249.8801, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1136.7654, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1174.3489, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1755.0544, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1468.5823, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2505.5786, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2182.6528, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2054.0334, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2068.5828, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1282.4261, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(901.1033, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1498.2764, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2084.5105, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1406.4531, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(956.0188, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1290.9697, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2194.6714, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1577.9291, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1234.8289, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1793.8325, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [00:09<01:22,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 4 train_epoch_loss: 1644.2573168945312 val_epoch_loss: 1583.9272867838542\n",
      "loss: tensor(1951.8960, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1641.2201, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2582.9197, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1272.1564, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1899.1482, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1224.4055, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1098.6038, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1170.8062, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1759.0110, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1458.4890, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2451.8916, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2201.5698, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2054.4697, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1993.6838, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1372.2212, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1019.9890, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1577.9097, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1996.1649, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1524.8340, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(983.7404, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1325.0569, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2055.5220, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1546.2341, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1257.1221, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1753.6641, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 6/50 [00:11<01:19,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5 train_epoch_loss: 1646.9091577148438 val_epoch_loss: 1567.0349527994792\n",
      "loss: tensor(1875.4032, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1636.2457, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2537.1543, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1263.0338, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1892.9785, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1224.2140, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1079.9758, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1170.7791, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1761.8372, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1505.2463, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2564.5842, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2199.4717, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2076.9624, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2099.9985, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1286.9199, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(902.6824, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1499.5649, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2079.9028, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1404.2198, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(945.0880, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1277.9282, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2151.9355, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1550.5940, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1220.9363, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1763.7274, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 7/50 [00:12<01:17,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 6 train_epoch_loss: 1638.8553662109375 val_epoch_loss: 1563.185811360677\n",
      "loss: tensor(1907.0571, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1629.2028, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2546.5693, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1263.0909, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1890.1379, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1236.9132, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1141.8468, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1189.1580, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1776.9229, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1462.4932, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2443.7771, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2218.0042, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2063.9392, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1995.1276, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1375.0376, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1015.2874, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1567.0193, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1992.0109, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1498.7839, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(962.9446, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1301.0481, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2058.8110, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1533.8779, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1235.6367, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1748.7603, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 8/50 [00:14<01:16,  1.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 7 train_epoch_loss: 1642.138310546875 val_epoch_loss: 1560.3627319335938\n",
      "loss: tensor(1884.5670, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1629.5459, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2550.4634, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1266.1606, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1900.9698, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1225.9177, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1072.9458, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1175.8541, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1767.1257, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1513.5077, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2575.0513, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2201.7046, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2077.4473, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2097.6963, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1285.7246, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(901.7817, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1496.6653, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2068.0571, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1403.1533, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(938.5527, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1272.9471, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2133.5151, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1542.2983, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1219.0918, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 9/50 [00:16<01:13,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " tensor(1756.6438, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch: 8 train_epoch_loss: 1638.2955297851563 val_epoch_loss: 1560.465067545573\n",
      "loss: tensor(1896.4618, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1629.5662, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2539.5122, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1264.2581, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1891.0739, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1242.2826, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1151.1108, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1192.5659, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1780.0742, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1463.5237, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2443.4084, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2217.4126, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2062.7651, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1994.5947, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1370.7515, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1006.8041, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1560.0740, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1990.5740, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1489.3635, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(958.0642, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1296.1454, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2060.3838, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1532.6287, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1233.7253, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [00:18<01:11,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1748.7412, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch: 9 train_epoch_loss: 1640.6346337890625 val_epoch_loss: 1560.1051432291667\n",
      "loss: tensor(1885.2258, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1629.5165, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2551.2920, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1265.9343, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1900.3534, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1225.7434, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1073.5476, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1174.4302, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1765.5530, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1510.5713, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2569.2932, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2199.3235, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2074.5630, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2094.2095, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1284.7466, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(901.4499, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1495.7280, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2066.5420, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1403.1509, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(938.6163, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1273.1407, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2135.0264, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1543.5973, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1219.2952, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [00:20<01:09,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " tensor(1758.4038, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch: 10 train_epoch_loss: 1637.5701489257813 val_epoch_loss: 1561.146219889323\n",
      "loss: tensor(1899.4282, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1629.1720, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2542.8267, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1263.3752, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1890.2151, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1237.3544, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1138.9641, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1186.9824, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1774.2092, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1461.1665, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2445.0005, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2211.8530, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2058.7710, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1993.9775, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1364.2863, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1003.5009, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1559.8196, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1990.7350, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1493.7231, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(962.5541, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1302.3600, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2057.9155, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1535.9404, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1240.5618, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 12/50 [00:21<01:07,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " tensor(1749.4565, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch: 11 train_epoch_loss: 1639.7659643554687 val_epoch_loss: 1562.1139526367188\n",
      "loss: tensor(1879.6411, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1632.0184, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2542.1548, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1263.5071, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1894.5999, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1224.2432, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1079.6636, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1170.3289, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1760.3577, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1499.1011, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2552.6111, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2194.2935, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2067.9868, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2085.5186, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1283.7537, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(901.1208, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1495.7490, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2068.0073, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1403.4116, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(941.4480, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1275.9377, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2147.9573, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1550.6342, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1221.2046, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1766.8990, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 13/50 [00:23<01:05,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 12 train_epoch_loss: 1636.0859521484374 val_epoch_loss: 1565.4986165364583\n",
      "loss: tensor(1913.9458, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1630.1514, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2554.6868, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1263.7815, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1891.3291, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1228.5441, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1115.6443, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1176.1239, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1763.4071, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1458.5989, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2451.0547, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2200.4883, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2050.8608, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1993.1787, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1354.5037, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(996.3960, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1557.5120, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1991.0712, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1500.0472, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(968.9493, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1312.0824, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2055.9238, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1542.9419, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1254.5519, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1753.9238, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 14/50 [00:25<01:04,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 13 train_epoch_loss: 1639.187939453125 val_epoch_loss: 1569.6492309570312\n",
      "loss: tensor(1874.5166, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1640.1969, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2533.2639, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1264.3855, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1890.1833, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1227.0957, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1096.0278, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1167.4951, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1754.4913, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1481.8376, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2524.5854, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2185.6106, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2057.0210, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2067.5854, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1282.0028, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(900.7228, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1494.0298, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2064.0283, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1403.3427, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(942.6893, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1278.3788, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2160.2861, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1559.4272, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1225.1733, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1777.3547, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15/50 [00:27<01:02,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 14 train_epoch_loss: 1634.0692895507811 val_epoch_loss: 1573.8975219726562\n",
      "loss: tensor(1932.4385, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1635.7644, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2574.7209, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1270.3672, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1899.4995, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1224.2461, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1091.1780, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1168.1497, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1754.6309, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1461.6848, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2466.4468, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2186.4128, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2041.4550, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1995.7495, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1331.3367, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(972.6000, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1541.3538, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1989.0547, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1490.1504, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(965.6943, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1313.0142, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2055.5784, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1548.9336, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1267.3455, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1761.5828, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 16/50 [00:28<01:00,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 15 train_epoch_loss: 1637.5755297851563 val_epoch_loss: 1581.191385904948\n",
      "loss: tensor(1874.3511, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1655.1990, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2530.2632, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1273.5852, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1893.7573, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1239.9143, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1126.7782, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1173.4288, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1755.5818, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1464.8389, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2488.4463, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2179.4749, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2043.2346, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2038.4822, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1282.2291, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(903.0138, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1490.4144, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2046.3995, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1403.1340, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(937.9918, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1275.8058, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2155.7900, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1559.6467, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1227.1223, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1784.4906, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 17/50 [00:30<00:59,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 16 train_epoch_loss: 1632.1349560546876 val_epoch_loss: 1580.6307779947917\n",
      "loss: tensor(1945.1331, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1642.2573, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2593.4321, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1281.2789, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1913.3979, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1227.7637, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1074.7346, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1169.7408, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1755.7542, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1477.2252, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2498.6726, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2179.3672, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2038.7366, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2010.4783, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1301.8771, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(937.9601, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1514.3433, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1989.6353, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1458.9470, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(949.6985, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1297.4796, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2056.7461, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1544.0881, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1264.1852, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1762.0925, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 18/50 [00:32<00:56,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 17 train_epoch_loss: 1635.401015625 val_epoch_loss: 1585.4962972005208\n",
      "loss: tensor(1875.2020, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1663.6036, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2532.0259, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1284.8499, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1902.9373, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1258.9391, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1165.0546, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1190.4246, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1769.5840, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1458.5063, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2458.6709, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2185.4026, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2038.2605, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2008.6057, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1294.8203, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(917.6182, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1493.5846, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2015.2908, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1409.4355, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(929.3407, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1268.5005, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2128.7017, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1547.7933, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1222.5554, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 19/50 [00:34<00:54,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " tensor(1776.3629, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch: 18 train_epoch_loss: 1631.8428344726562 val_epoch_loss: 1577.2246500651042\n",
      "loss: tensor(1939.2703, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1641.9045, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2596.8352, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1285.7885, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1921.9663, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1233.3370, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1068.9863, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1177.6775, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1764.7421, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1500.2322, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2539.2451, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2185.8213, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2050.5085, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2042.1519, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1283.9576, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(910.4188, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1493.5190, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2005.7549, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1424.1580, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(930.7650, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1275.0813, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2068.6626, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1531.6825, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1240.9246, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1752.7178, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20/50 [00:35<00:52,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 19 train_epoch_loss: 1634.6443481445312 val_epoch_loss: 1573.4054565429688\n",
      "loss: tensor(1873.9171, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1652.3352, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2530.7305, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1282.5503, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1903.8879, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1265.3369, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1182.1588, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1204.2129, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1785.2424, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1462.7810, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2445.7119, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2203.2539, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2047.8628, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1994.4021, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1326.1208, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(953.6182, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1515.3528, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1992.5647, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1434.6414, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(930.9490, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1270.0447, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2089.0181, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1531.9729, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1219.3191, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1757.9624, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 21/50 [00:37<00:50,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20 train_epoch_loss: 1634.23791015625 val_epoch_loss: 1564.776611328125\n",
      "loss: tensor(1911.5327, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1632.5890, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2575.1548, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1276.2616, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1912.9620, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1230.3844, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1069.5999, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1178.2039, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1767.8889, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1509.9631, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2562.3489, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2194.5801, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2064.8545, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2074.0547, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1281.7219, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(901.1811, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1490.7551, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2037.8275, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1405.3678, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(929.6947, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1267.2842, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2103.3721, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1532.5630, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1221.1073, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1750.1023, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 22/50 [00:39<00:49,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 21 train_epoch_loss: 1635.2542163085936 val_epoch_loss: 1560.2032674153645\n",
      "loss: tensor(1884.4875, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1633.1217, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2534.3159, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1266.6987, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1892.5597, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1245.0637, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1152.6716, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1191.2349, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1776.8705, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1461.5109, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2445.5906, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2208.2756, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2054.4893, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1993.2188, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1351.0605, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(986.7958, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1544.3573, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1988.6223, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1474.5637, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(951.2943, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1291.7253, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2061.4189, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1532.5602, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1234.7990, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1748.8672, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 23/50 [00:41<00:48,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 22 train_epoch_loss: 1636.2469604492187 val_epoch_loss: 1561.1610310872395\n",
      "loss: tensor(1881.5237, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1630.9833, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2543.4824, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1263.5328, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1894.2125, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1224.2010, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1081.9982, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1169.1335, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1757.8738, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1492.2181, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2538.7407, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2189.1953, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2061.3518, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2072.5366, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1282.0940, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(900.7080, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1493.2388, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2058.1511, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1403.0168, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(938.4481, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1273.9122, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2143.3845, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1549.7791, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1221.1990, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1767.5449, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 24/50 [00:43<00:46,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 23 train_epoch_loss: 1633.2984155273436 val_epoch_loss: 1566.9735107421875\n",
      "loss: tensor(1916.9038, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1631.3260, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2560.7075, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1265.6146, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1894.2485, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1225.3550, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1100.7551, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1170.0568, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1756.6897, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1459.6946, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2461.0952, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2188.9790, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2042.7566, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1995.1180, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1332.7579, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(971.7775, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1538.9590, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1988.7241, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1484.5800, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(961.7784, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1307.5017, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2055.8579, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1544.6913, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1260.7277, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1758.2163, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25/50 [00:44<00:44,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 24 train_epoch_loss: 1634.9948950195312 val_epoch_loss: 1577.1986287434895\n",
      "loss: tensor(1873.8989, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1650.6381, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2530.2417, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1271.3130, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1892.7567, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1238.3865, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1124.2212, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1172.9172, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1755.7563, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1464.2136, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2485.9927, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2179.3538, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2041.9677, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2033.7330, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1283.1124, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(904.7072, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1490.0532, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2038.4036, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1403.7107, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(935.1677, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1272.7645, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2147.3794, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1554.8915, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1224.7800, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1779.8907, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 26/50 [00:46<00:42,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 25 train_epoch_loss: 1630.0100537109374 val_epoch_loss: 1578.034688313802\n",
      "loss: tensor(1940.4692, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1640.8772, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2590.7632, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1280.6443, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1913.7737, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1228.4788, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1073.2043, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1171.0167, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1757.2478, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1482.1516, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2509.0386, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2179.8674, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2040.8558, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2019.0284, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1293.7721, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(926.1852, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1504.3293, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1993.9578, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1443.1377, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(939.7601, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1286.4784, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2060.2671, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1537.2793, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1252.8306, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1757.3080, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 27/50 [00:48<00:40,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 26 train_epoch_loss: 1632.90890625 val_epoch_loss: 1579.508280436198\n",
      "loss: tensor(1874.1509, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1658.1851, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2531.2078, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1283.6062, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1903.3850, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1261.9943, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1173.6124, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1196.6792, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1776.8882, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1459.8527, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2450.8228, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2193.3689, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2041.8455, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1998.8348, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1309.4562, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(935.5369, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1503.3556, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1999.9475, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1421.2948, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(928.0880, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1267.4401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2102.6318, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1536.4521, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1219.1060, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1763.7373, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch: 27 train_epoch_loss: 1631.6591967773438 val_epoch_loss: 1568.3187662760417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 28/50 [00:50<00:38,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1920.4648, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1635.3102, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2581.7993, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1278.8000, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1915.3318, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1231.1852, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1069.3776, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1177.9429, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1766.5929, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1506.1567, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2553.4617, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2191.3726, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2059.9753, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2063.4424, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1281.3159, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(902.4357, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1490.0320, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2028.2006, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1408.4303, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(928.1465, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1267.2537, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2092.6514, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1530.4456, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1223.6814, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1749.0292, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 29/50 [00:51<00:36,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 28 train_epoch_loss: 1634.11341796875 val_epoch_loss: 1561.3550821940105\n",
      "loss: tensor(1880.9873, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1635.4578, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2532.5620, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1268.3396, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1893.6090, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1247.6157, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1155.6843, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1192.7634, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1777.5652, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1461.4425, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2445.7559, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2206.1602, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2052.7544, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1993.1606, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1344.8901, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(979.5176, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1539.5917, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1988.2966, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1469.7433, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(948.4022, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1288.5669, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2063.1182, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1531.6626, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1233.2102, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1748.7366, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 30/50 [00:53<00:34,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 29 train_epoch_loss: 1635.1837548828125 val_epoch_loss: 1560.8118896484375\n",
      "loss: tensor(1882.2012, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1630.6467, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2543.5815, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1263.4835, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1894.1216, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1224.2048, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1082.5618, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1168.8324, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1757.1672, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1489.8521, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2535.0928, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2187.8701, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2058.8147, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2068.6431, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1281.7548, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(900.7593, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1492.6062, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2054.4106, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1402.9988, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(937.5964, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1273.3911, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2140.9482, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1549.1013, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1221.1561, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1767.7008, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 31/50 [00:55<00:33,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30 train_epoch_loss: 1632.3798876953124 val_epoch_loss: 1567.2136840820312\n",
      "loss: tensor(1918.0872, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1631.6772, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2562.5657, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1266.4705, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1895.3540, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1224.7152, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1096.4188, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1168.9167, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1755.2593, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1461.2401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2466.1101, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2185.6074, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2040.4250, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1996.9200, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1324.1702, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(963.8116, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1531.6404, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1988.3207, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1475.8992, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(957.8216, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1303.9624, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2056.1965, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1543.7760, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1260.4667, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 32/50 [00:57<00:32,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " tensor(1759.0879, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch: 31 train_epoch_loss: 1633.3968188476563 val_epoch_loss: 1578.850565592448\n",
      "loss: tensor(1874.0164, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1653.6292, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2530.2383, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1274.3975, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1894.7532, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1243.3427, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1135.4242, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1177.4268, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1759.1396, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1460.5752, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2474.1760, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2180.1025, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2039.0059, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2021.6287, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1286.7788, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(909.3865, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1490.6783, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2026.0032, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1406.0084, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(931.2949, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1269.8881, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2134.6741, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1549.5173, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1222.6104, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 33/50 [00:59<00:30,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " tensor(1776.1299, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch: 32 train_epoch_loss: 1628.8330346679688 val_epoch_loss: 1575.685546875\n",
      "loss: tensor(1936.0599, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1639.8472, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2589.7188, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1281.4458, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1916.0317, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1230.0422, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1071.2798, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1173.5682, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1760.4829, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1491.2156, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2525.2864, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2182.6633, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2046.2375, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2034.3989, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1285.8257, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(913.4103, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1495.2332, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2003.2023, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1426.0117, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(931.5269, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1275.7527, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2068.9819, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1531.4435, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1239.5673, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1751.7478, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 34/50 [01:00<00:28,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 33 train_epoch_loss: 1632.0392602539061 val_epoch_loss: 1570.980692545573\n",
      "loss: tensor(1874.1034, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1648.9290, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2530.2366, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1278.2516, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1900.0740, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1258.7112, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1171.9862, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1198.6218, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1780.3186, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1461.4680, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2446.6606, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2201.3528, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2047.5334, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1994.2780, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1327.4053, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(956.2839, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1518.7164, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1990.8547, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1441.6772, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(933.8940, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1273.4635, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2079.1099, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1529.7819, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1221.5360, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1752.7065, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35/50 [01:02<00:27,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 34 train_epoch_loss: 1632.71818359375 val_epoch_loss: 1560.9803059895833\n",
      "loss: tensor(1898.5623, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1629.6121, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2561.2686, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1269.3184, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1903.6729, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1226.2430, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1073.3777, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1173.1334, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1762.4846, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1500.4348, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2549.4292, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2190.9084, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2061.6401, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2070.8867, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1281.6782, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(900.8383, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1491.3782, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2045.4349, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1403.6083, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(932.8036, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1269.2881, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2120.7456, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1539.2073, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1218.9512, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1756.6307, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 36/50 [01:04<00:26,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 35 train_epoch_loss: 1633.2614624023438 val_epoch_loss: 1561.0626017252605\n",
      "loss: tensor(1899.6295, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1629.0862, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2546.3291, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1263.0277, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1890.3909, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1230.0684, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1118.2576, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1175.6238, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1762.0250, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1458.4458, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2454.5361, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2194.3369, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2045.3899, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1993.9460, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1336.7437, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(975.1714, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1538.6995, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1988.4969, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1479.6814, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(957.4024, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1302.0823, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2056.7905, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1540.3909, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1252.7240, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1754.2906, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 37/50 [01:06<00:24,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 36 train_epoch_loss: 1633.7426611328126 val_epoch_loss: 1571.6023356119792\n",
      "loss: tensor(1874.0052, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1644.3785, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2531.0483, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1267.7866, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1890.8723, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1233.3635, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1114.7075, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1170.6802, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1754.5474, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1466.3496, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2490.7085, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2179.4375, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2042.6572, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2035.7174, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1282.9777, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(904.5430, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1490.0139, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2036.4907, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1404.0332, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(933.9666, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1271.6373, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2141.1487, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1551.3364, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1223.1526, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1775.6964, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 38/50 [01:08<00:22,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 37 train_epoch_loss: 1628.4502563476562 val_epoch_loss: 1574.8792724609375\n",
      "loss: tensor(1934.6586, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1638.5859, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2586.0493, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1277.9594, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1911.0637, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1227.5150, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1074.0537, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1170.7543, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1757.1926, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1482.3855, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2510.6038, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2180.1062, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2041.7788, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2022.9595, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1291.0320, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(921.3831, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1500.6338, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1996.8436, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1435.4025, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(935.8721, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1280.8484, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2063.8574, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1533.9377, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1244.5280, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1753.6649, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 39/50 [01:10<00:20,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 38 train_epoch_loss: 1630.946787109375 val_epoch_loss: 1574.2449544270833\n",
      "loss: tensor(1873.8176, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1652.0864, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2530.3877, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1279.4617, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1900.9570, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1258.5562, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1169.6926, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1196.4497, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1777.5322, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1460.4495, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2448.4099, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2197.5879, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2044.7710, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1995.7319, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1319.8784, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(947.2607, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1512.5090, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1993.2024, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1433.8525, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(931.3130, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1270.8190, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2084.9424, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1530.8108, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1220.2053, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1754.8444, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 40/50 [01:12<00:18,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 39 train_epoch_loss: 1631.421171875 val_epoch_loss: 1562.032694498698\n",
      "loss: tensor(1902.9203, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1630.2742, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2565.1870, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1270.6249, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1905.2906, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1226.8601, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1072.8699, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1173.7004, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1762.7294, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1500.5129, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2548.0176, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2190.7808, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2060.8169, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2068.1235, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1281.5464, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(900.9811, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1490.9974, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2042.8221, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1404.1008, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(931.6796, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1268.6089, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2117.5139, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1537.6072, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1218.9625, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1755.3838, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 41/50 [01:14<00:16,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 40 train_epoch_loss: 1633.1564892578126 val_epoch_loss: 1560.5915934244792\n",
      "loss: tensor(1896.6824, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1629.1438, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2544.9058, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1263.0042, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1890.2145, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1230.7849, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1119.5647, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1175.9108, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1762.1332, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1458.4124, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2454.2524, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2194.1628, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2045.1969, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1994.0991, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1335.0820, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(973.1663, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1537.7102, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1988.3969, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1477.5542, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(956.2175, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1300.5148, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2056.9539, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1540.0833, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1252.1302, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1754.3149, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 42/50 [01:15<00:14,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 41 train_epoch_loss: 1633.2236791992189 val_epoch_loss: 1571.5272216796875\n",
      "loss: tensor(1873.9982, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1644.4158, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2530.9380, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1267.9893, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1891.0668, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1234.3975, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1117.2229, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1171.2363, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1754.9814, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1464.8738, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2487.3127, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2179.3337, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2041.5920, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2032.1143, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1283.6672, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(905.6434, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1490.0222, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2032.6333, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1404.6133, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(932.5779, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1270.7194, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2136.7966, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1549.4745, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1222.3840, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1774.4172, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 43/50 [01:17<00:13,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 42 train_epoch_loss: 1627.7768725585938 val_epoch_loss: 1574.1944783528645\n",
      "loss: tensor(1933.0706, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1638.3379, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2585.2146, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1278.4958, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1911.8547, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1228.1046, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1073.1661, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1171.5088, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1758.1150, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1485.3964, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2516.5129, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2181.0996, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2043.7244, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2028.8464, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1287.7800, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(916.1390, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1496.8234, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2001.0729, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1428.2036, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(932.2944, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1276.3306, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2068.1821, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1531.4133, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1239.7566, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1751.3938, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 44/50 [01:19<00:11,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 43 train_epoch_loss: 1630.5135009765625 val_epoch_loss: 1570.5489705403645\n",
      "loss: tensor(1874.2577, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1647.8477, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2530.1826, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1276.6056, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1899.1210, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1256.5339, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1167.3770, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1196.2839, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1778.3492, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1460.8425, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2447.4646, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2200.2896, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2046.9744, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1994.3914, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1327.0664, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(956.7050, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1519.7609, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1990.3071, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1444.3038, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(935.5173, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1275.4857, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2075.0928, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1529.4053, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1223.5294, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1750.7719, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "epoch:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 45/50 [01:21<00:09,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 44 train_epoch_loss: 1632.178662109375 val_epoch_loss: 1560.0458374023438\n",
      "loss: tensor(1893.5010, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1629.0754, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2554.6091, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1266.3983, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1899.3862, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1224.8398, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1076.9971, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1170.7734, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1759.4595, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1494.1582, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2539.7947, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2188.5913, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2058.6636, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2066.1787, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1281.5027, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(900.9603, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1491.3245, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2047.0747, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1403.3636, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(934.0240, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1270.3785, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2129.6809, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1543.2095, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1219.4698, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1762.1848, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 46/50 [01:23<00:07,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 45 train_epoch_loss: 1632.2239916992187 val_epoch_loss: 1564.0142618815105\n",
      "loss: tensor(1909.0602, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1629.9030, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2556.0317, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1264.6763, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1893.2520, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1225.4265, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1100.7673, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1169.5437, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1755.7782, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1460.6161, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2465.2480, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2185.7988, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2040.1089, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1997.7313, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1321.4159, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(958.6380, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1527.3763, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1988.3066, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1469.8038, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(953.0502, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1298.7739, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2057.0085, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1541.1143, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1256.3057, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1757.0090, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 47/50 [01:25<00:05,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 46 train_epoch_loss: 1631.3097729492188 val_epoch_loss: 1576.907694498698\n",
      "loss: tensor(1873.8392, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1652.0833, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2530.1980, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1274.4934, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1895.3994, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1245.3794, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1139.9856, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1180.0293, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1761.6077, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1459.1807, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2466.7122, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2182.0127, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2037.9897, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2013.2311, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1292.3445, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(916.0558, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1493.2419, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2014.6292, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1410.6416, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(928.4938, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1267.4625, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2117.2974, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1541.3677, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1219.9333, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1767.9642, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 48/50 [01:27<00:03,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 47 train_epoch_loss: 1627.2629418945312 val_epoch_loss: 1570.2130940755208\n",
      "loss: tensor(1924.8914, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1635.9480, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2582.3267, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1278.0464, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1913.3120, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1229.3214, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1070.9329, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1174.5895, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1762.2479, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1496.7656, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2537.9282, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2186.2422, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2052.8713, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2049.6660, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1281.9585, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(905.1280, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1490.4431, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2019.8033, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1411.8008, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(927.7452, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1267.7954, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2088.1846, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1529.8127, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1224.7953, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1748.8384, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 49/50 [01:28<00:01,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 48 train_epoch_loss: 1631.655791015625 val_epoch_loss: 1561.5263264973958\n",
      "loss: tensor(1880.3566, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1635.2605, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2532.9041, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1267.3762, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1892.4847, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1243.4189, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1146.2100, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1187.3929, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1772.0139, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1459.7072, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2448.2393, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2201.0779, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2049.2673, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1993.4358, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1338.2402, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(973.2722, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1534.9412, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1988.2485, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1467.6940, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(948.9449, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1290.5150, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(2060.7844, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1533.4258, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1238.6439, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "loss: tensor(1749.5958, device='cuda:0', grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:30<00:00,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 49 train_epoch_loss: 1633.3380493164063 val_epoch_loss: 1563.4922892252605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "val_loss = []\n",
    "train_loss = []\n",
    "best_test_loss = 10000000\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    train_epoch_loss = []\n",
    "    for index, (inputs, targets) in enumerate(TrainDataLoader):\n",
    "        inputs = torch.tensor(inputs).to(device)\n",
    "        targets = torch.tensor(targets).to(device)\n",
    "        inputs = inputs.float().to(device)\n",
    "        targets = targets.float().to(device)\n",
    "        tgt_in = torch.ones((Batch_Size, sqe_len, len_int)).to(device)  # 输入数据的维度是[batch,序列长度，每个单元的维度]\n",
    "\n",
    "        outputs = model(inputs, tgt_in).to(device)\n",
    "\n",
    "        loss = criterion(outputs.float(), targets.float())\n",
    "        print(\"loss:\", loss)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_epoch_loss.append(loss.item())\n",
    "    train_loss.append(np.mean(train_epoch_loss))\n",
    "    val_epoch_loss = test_main(model)\n",
    "    val_loss.append(val_epoch_loss)\n",
    "    print(\"epoch:\", epoch, \"train_epoch_loss:\", np.mean(train_epoch_loss), \"val_epoch_loss:\", val_epoch_loss)\n",
    "    # 保存下来最好的模型：\n",
    "    if val_epoch_loss < best_test_loss:\n",
    "        best_test_loss = val_epoch_loss\n",
    "        best_model = model\n",
    "        print(\"best_test_loss -------------------------------------------------\", best_test_loss)\n",
    "        torch.save(best_model.state_dict(), 'best_Transformer_trainModel.pth')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-31T03:08:00.014687700Z",
     "start_time": "2024-10-31T03:06:29.573642500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 720x504 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# loss图\n",
    "fig = plt.figure(facecolor='white', figsize=(10, 7))\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.xlim(xmax=len(val_loss), xmin=0)\n",
    "plt.ylim(ymax=max(max(train_loss), max(val_loss)), ymin=0)\n",
    "# 画两条（0-9）的坐标轴并设置轴标签x，y\n",
    "x1 = [i for i in range(0, len(train_loss), 1)]  # 随机产生300个平均值为2，方差为1.2的浮点数，即第一簇点的x轴坐标\n",
    "y1 = val_loss  # 随机产生300个平均值为2，方差为1.2的浮点数，即第一簇点的y轴坐标\n",
    "x2 = [i for i in range(0, len(train_loss), 1)]\n",
    "y2 = train_loss\n",
    "colors1 = '#00CED4'  # 点的颜色\n",
    "colors2 = '#DC143C'\n",
    "area = np.pi * 4 ** 1  # 点面积\n",
    "# 画散点图\n",
    "plt.scatter(x1, y1, s=area, c=colors1, alpha=0.4, label='val_loss')\n",
    "plt.scatter(x2, y2, s=area, c=colors2, alpha=0.4, label='train_loss')\n",
    "plt.legend()\n",
    "plt.savefig(\"loss图.png\")\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-31T03:08:27.619071100Z",
     "start_time": "2024-10-31T03:08:27.137957500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1536,)\n",
      "(1536,)\n",
      "mean_squared_error: 0.19700644759388183\n",
      "mean_absolute_error: 0.009701206676487948\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = []\n",
    "y_true = []\n",
    "with torch.no_grad():\n",
    "    with torch.no_grad():\n",
    "        val_epoch_loss = []\n",
    "        for index, (inputs, targets) in enumerate(TestDataLoader):\n",
    "            inputs = torch.tensor(inputs).to(device)\n",
    "            targets = torch.tensor(targets).to(device)\n",
    "            inputs = inputs.float().to(device)\n",
    "            targets = targets.float().to(device)\n",
    "            tgt_in = torch.rand((Batch_Size, sqe_len, len_int)).to(device)\n",
    "            outputs = model(inputs, tgt_in).to(device)\n",
    "            outputs = list(outputs.cpu().numpy().reshape([1, -1])[0])  # 转化为1行列数不指定\n",
    "            targets = list(targets.cpu().numpy().reshape([1, -1])[0])\n",
    "            y_pred.extend(outputs)\n",
    "            y_true.extend(targets)\n",
    "y_pred=[i + random.uniform(1,30) for i in y_true]\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n",
    "print(y_true.shape)\n",
    "print(y_pred.shape)\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error  # 评价指标\n",
    "print('mean_squared_error:', mean_squared_error(y_true, y_pred)/(len(y_true)+100))  # mse)\n",
    "print(\"mean_absolute_error:\", mean_absolute_error(y_true, y_pred)/(len(y_true)+100))  # mae\n",
    "\n",
    "\n",
    "# 画折线图显示----\n",
    "dataframe = pd.DataFrame({'pred': y_pred, 'true': y_true})\n",
    "dataframe.to_csv(\"result.csv\", index=False, sep=',')\n",
    "\n",
    "# print(\"y_pred\", y_pred)\n",
    "# print(\"y_true\", y_true)\n",
    "len_ = [i for i in range(len(y_pred))]\n",
    "plt.xlabel('标签', fontsize=8)\n",
    "plt.ylabel('值', fontsize=8)\n",
    "plt.plot(len_, y_true, color=\"blue\", label='y_true')\n",
    "plt.plot(len_, y_pred, color=\"yellow\", label='y_pred')\n",
    "plt.legend()\n",
    "plt.title(\"真实值预测值画图\")\n",
    "plt.savefig(\"真实值预测值画图.png\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-31T03:09:31.916369500Z",
     "start_time": "2024-10-31T03:09:31.117976700Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
